{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weapon Detection and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Author: Anita Camlic`\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A one-paragraph overview of the project, including the business problem, data, methods, results and recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Forbes' magazine, in the United States there have been 611 mass shootings so far this year (2022). As of Nov. 25 2022,  **39,935**  people have died from gun-related events in the U.S. this year, including **18,221** who died by homicide, murder or an unintentional shooting, plus another 21,714 who died by suicide.\n",
    "\n",
    "Of those victims, **291 were children ages 0-11, and 1,225 were teens ages 12-17**. Gun violence is an epidemic. \n",
    "\n",
    "There is currently no systemic solution to gun violence in the United States. Though there has not been systemic changes to gun violence in the United States, there have been technological advancements that can be applied to this problem. One of those improvements being Convolutional Neural Networks. Convolutional Neural Networks can be used to identify patterns in images. For example, Convolutional Neural Networks can be used to differentiate between a cat and a dog in an image. They are used in applications like facial recognition for the Iphone and image tagging on facebook. Technology like this can also be used on videos, for applications like self driving cars and object detection. \n",
    "\n",
    "For my project, I will be using Convolutional Neural Networks to classify images as either holding a gun or holding a common handheld object. My project is a binary classification model. Since a lot of handheld devices (phone, wallet, credit card) can be mistaken as a gun (and vice versa), I plan to train a model to be able to make that distinction. This type of modeling could eventually be applied to surveillance cameras on public areas like schools, grocery stores, movie theaters and more. Hopefully this problem can be broadened upon in the future to reduce the amount of gun-related deaths and injuries in the United States.\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the business problem you are trying to solve, and the data questions that you plan to answer to solve them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions to consider:\n",
    "\n",
    "What are the business's pain points related to this project?\n",
    "How did you pick the data analysis question(s) that you did?\n",
    "Why are these questions important from a business perspective?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schools need assurance that their students will be kept safe while at school. Children should not have to worry about being a victim of gun violence while they are at school. School should not be a place of fear. It should be a place of nurturing, learning and growing. To combat against this fear that many have, I have created an Image classification model that will differentiate common handheld object and guns. This will make it easier for a school to recognize a threat and react accordingly. It could even trigger some sort of alarm or at least a call to the police. This can be used as a first line of defense against mass shooters. However, this should not be the only sort of defense. This is simply a tool that can quickly and effeciently classify a gun vs other hanheld objects. The main point of this system is to save time, and to get help to the area sooner in hopes to mitigate any potential damage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Though this model is directed towards public school disctrics, it is not limited to schools. I would like to see it implemented in all public spaces like grocery stores, government buildings, banks, shopping malls, places of worship, and many more.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the data being used for this project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions to consider:\n",
    "\n",
    "Where did the data come from, and how do they relate to the data analysis questions?\n",
    "What do the data represent? Who is in the sample and what variables are included?\n",
    "What is the target variable?\n",
    "What are the properties of the variables you intend to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data I used for this project is from the University of Granada's Andalusian Research Institute in Data Science and Computational Intelligence. The data is open data and able to be downloaded at the link below. \n",
    "\n",
    "The dataset I used specifically for this project was dataset 2.3 Weapons and similar handled object detection. [Dataset found here](https://github.com/ari-dasci/OD-WeaponDetection/tree/master/Weapons%20and%20similar%20handled%20objects) This dataset contains over 5,000 images of various weapons (knives, guns) and common handheld objects (wallet, credit card, cellphone, dollar bills). \n",
    "\n",
    "\n",
    "I did not include the data in the github because it was too large to fit. Below is the link to all of the datasets from the weapon detection project at the University of Granada's Andalusian Research Institute in Data Science and Computational Intelligence.\n",
    "\n",
    "[All Weapon Detection Data](https://dasci.es/transferencia/open-data/24705/)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my specific business problem, I wanted to work with guns. So for my data preperation I first removed all of the images of knives and only kept the images containing guns. I also removed and images with just a gun on a blank surface. That will not help in a practical application. Being able to detect a gun on a blank surface might be good for an application in TSA, however for surveillance applications and trying to flag for an individual holding a gun, it wouldn't help much and it might confuse my model even more. \n",
    "*** \n",
    "\n",
    "After I removed certain images, I then created a folder on my desktop for my data to live. I did this because my data was to large to keep on github, so I had to keep it in a folder on my computer. Then I classified them by hand in different folders as either 0 (containing no weapon) or 1 (containing a weapon). After this, I saved the absolute path as a string in my Jupyter Notebook and I used ImageDataGenerator objects to help prepare my images for modeling. \n",
    "\n",
    "ImageDataGenerator takes in a path to your data, and transforms it for modeling. You just specift and rescaling you want to do, and augmenting you want to do and it will perform those transformations and return an instance to be fed right into your Convolutional Neural Network.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________\n",
    "\n",
    "Describe and justify the process for analyzing or modeling the data.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "How did you analyze or model the data?\n",
    "How did you iterate on your initial approach to make it better?\n",
    "Why are these choices appropriate given the data and the business problem?\n",
    "______________________________________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________\n",
    "Evaluate how well your work solves the stated business problem.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "How do you interpret the results?\n",
    "How well does your model fit your data? How much better is this than your baseline model?\n",
    "How confident are you that your results would generalize beyond the data you have?\n",
    "How confident are you that this model would benefit the business if put into use?\n",
    "______________________________________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide your conclusions about the work you've done, including any limitations or next steps.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "What would you recommend the business do as a result of this work?\n",
    "What are some reasons why your analysis might not fully solve the business problem?\n",
    "What else could you do in the future to improve this project?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
