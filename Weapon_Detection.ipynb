{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weapon Detection and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Author: Anita Camlic`\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A one-paragraph overview of the project, including the business problem, data, methods, results and recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Forbes' magazine, in the United States there have been 611 mass shootings so far this year (2022). As of Nov. 25 2022,  **39,935**  people have died from gun-related events in the U.S. this year, including **18,221** who died by homicide, murder or an unintentional shooting, plus another 21,714 who died by suicide.\n",
    "\n",
    "Of those victims, **291 were children ages 0-11, and 1,225 were teens ages 12-17**. Gun violence is an epidemic. \n",
    "\n",
    "There is currently no systemic solution to gun violence in the United States. Though there has not been systemic changes to gun violence in the United States, there have been technological advancements that can be applied to this problem. One of those improvements being Convolutional Neural Networks. Convolutional Neural Networks can be used to identify patterns in images. For example, Convolutional Neural Networks can be used to differentiate between a cat and a dog in an image. They are used in applications like facial recognition for the Iphone and image tagging on facebook. Technology like this can also be used on videos, for applications like self driving cars and object detection. \n",
    "\n",
    "For my project, I will be using Convolutional Neural Networks to classify images as either holding a gun or holding a common handheld object. My project is a binary classification model. Since a lot of handheld devices (phone, wallet, credit card) can be mistaken for a gun (and vice versa), I plan to train a model to be able to make that distinction. This type of modeling could eventually be applied to surveillance cameras on public areas like schools, grocery stores, movie theaters and more. Hopefully this problem can be broadened upon in the future to reduce the amount of gun-related deaths and injuries in the United States.\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the business problem you are trying to solve, and the data questions that you plan to answer to solve them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions to consider:\n",
    "\n",
    "What are the business's pain points related to this project?\n",
    "How did you pick the data analysis question(s) that you did?\n",
    "Why are these questions important from a business perspective?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schools need assurance that their students will be kept safe while at school. Children should not have to worry about being a victim of gun violence while they are at school. School should not be a place of fear. It should be a place of nurturing, learning and growing. To combat this fear that many have, I have created an Image classification model that will differentiate common handheld objects and guns. This will make it easier for a school to recognize a threat and react accordingly. It could even trigger some sort of alarm or at least a call to the police. This can be used as a first line of defense against mass shooters. However, this should not be the only sort of defense. This is simply a tool that can quickly and  efficiently classify a gun vs other handheld objects. The main point of this system is to save time, and to get help to the area sooner in hopes to mitigate any potential damage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Though this model is directed towards public school districts, it is not limited to schools. I would like to see it implemented in all public spaces like grocery stores, government buildings, banks, shopping malls, places of worship, and many more.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the data being used for this project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions to consider:\n",
    "\n",
    "Where did the data come from, and how do they relate to the data analysis questions?\n",
    "What do the data represent? Who is in the sample and what variables are included?\n",
    "What is the target variable?\n",
    "What are the properties of the variables you intend to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data I used for this project is from the University of Granada's Andalusian Research Institute in Data Science and Computational Intelligence. The data is open data and able to be downloaded at the link below. \n",
    "\n",
    "The dataset I used specifically for this project was dataset 2.3 Weapons and similar handled object detection. [Dataset found here](https://github.com/ari-dasci/OD-WeaponDetection/tree/master/Weapons%20and%20similar%20handled%20objects) This dataset contains over 5,000 images of various weapons (knives, guns) and common handheld objects (wallet, credit card, cellphone, dollar bills). \n",
    "\n",
    "\n",
    "I did not include the data in the github because it was too large to fit. Below is the link to all of the datasets from the weapon detection project at the University of Granada's Andalusian Research Institute in Data Science and Computational Intelligence.\n",
    "\n",
    "[All Weapon Detection Data](https://dasci.es/transferencia/open-data/24705/)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my specific business problem, I wanted to work with guns. So for my data preparation I first removed all of the images of knives and only kept the images containing guns. I also removed images with just a gun on a blank surface. That will not help in a practical application. Being able to detect a gun on a blank surface might be good for an application in TSA, however for surveillance applications and trying to flag for an individual holding a gun, it wouldn't help much and it might confuse my model even more. \n",
    "*** \n",
    "\n",
    "After I removed certain images, I then created a folder on my desktop for my data to live. I did this because my data was too large to keep on github, so I had to keep it in a folder on my computer. Then I classified them by hand in different folders as either 0 (containing no weapon) or 1 (containing a weapon). After this, I saved the absolute path as a string in my Jupyter Notebook and I used ImageDataGenerator objects to help prepare my images for modeling. \n",
    "\n",
    "ImageDataGenerator takes in a path to your data, and transforms it for modeling. You just specify and rescale what you want to do, and augment what you want to do and it will perform those transformations and return an instance to be fed right into your Convolutional Neural Network.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________\n",
    "\n",
    "For modeling, I started with the baseline model right below this cell. \n",
    "\n",
    "My baseline model consisted of:\n",
    "\n",
    "* 1 Convolutional layer with `32 nodes`, `reLu activation`, `(3,3) kernel size`\n",
    "* 1 Max Pooling layer with `(2,2) pool size`\n",
    "* 1 Convolutional layer with `32 nodes`, `reLu activation`, `(4,4) kernel size`\n",
    "* 1 Max Pooling layer with `(2,2) pool size`\n",
    "* 1 Convolutional layer with `64 nodes`, `reLu activation`, `(3,3) kernel size`\n",
    "* 1 Max Pooling layer with `(2,2) pool size`\n",
    "* 1 Flattening layer - layer that flattens the tensor into a 1D array to be fed into the dense layers\n",
    "* Dense Layer 1 - Dense layer with `64 nodes` and `reLu activation`\n",
    "* Dense Layer 2 - output layer with `sigmoid activation`\n",
    "\n",
    "\n",
    "The reason this is my baseline is because this is a good starting place for a Convolutional Neural Network. There are layers that can be taken away, hyperparameters that can be tweaked, and a lot that can be added. I felt as though for my data, this was a good starting place for me. \n",
    "\n",
    "\n",
    "As you scroll further you may notice that I struggled quite a bit with overfitting. My model was working really well with my training data, but not generalizing well to the patterns in my data. It was like my model was just memorizing the images in the training data. My training scores rose to 100% quite quickly, however, my validation scores were still quite low.\n",
    "\n",
    "So, the next order of business is reducing overfitting. With Convolutional Neural Networks, and with Neural Networks in general, it's really easy to create a model that is overfit. This is because there are so many parameters that the model has to keep track of and update. Not to mention when images are your data, the pixel values become your data, and generally, images need to have a high amount of pixels to be able to be recognized as anything meaningful by the naked eye, let alone a computer. So, a lot of data, and a lot of parameters/hyperparameters leads to high complexity. High complexity means low bias and high variance, which is a recipe for overfitting of data.\n",
    "\n",
    "I experimented with doing many things to not only my model but also my data. I tweaked many things and documented every step of the way. Instead of writing it all here, I wrote some lines before each model iteration about what I was attempting to do, and what I was changing. \n",
    "______________________________________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________\n",
    "Evaluate how well your work solves the stated business problem.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "How do you interpret the results?\n",
    "How well does your model fit your data? How much better is this than your baseline model?\n",
    "How confident are you that your results would generalize beyond the data you have?\n",
    "How confident are you that this model would benefit the business if put into use?\n",
    "\n",
    "\n",
    "\n",
    "* create a function to find recall, precision, and F1 Score, just to maybe add it to our analysis\n",
    "\n",
    "\n",
    "As for metrics, currently \n",
    "______________________________________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea 2: Maybe Examples of images that were correctly classified and incorrectly classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar chart of Different Model Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide your conclusions about the work you've done, including any limitations or next steps.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "What would you recommend the business do as a result of this work?\n",
    "What are some reasons why your analysis might not fully solve the business problem?\n",
    "What else could you do in the future to improve this project?\n",
    "\n",
    "### Conclusions and Recommendations\n",
    "\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Some limitations I ran into for this project were data, computational power and lack of time.\n",
    "\n",
    "<u>**Data Limitations**</u>\n",
    "For my data, I think there is a lack of cohesiveness which is confusing my model. In my data I have a mixture of images of strictly hands holding common handheld objects/firearms. However, I also have images of greater / larger scenes where there are full people holding the object of interest. I think my model is getting stuck and confused on the various types of images it is being trained on, because if you look at them side by side they are very different, and generalizing to two different types of images with different backgrounds, and multiple subjects is a difficult task in itself.\n",
    "\n",
    "I think that for this starting project, I probably should have strictly stuck to JUST images of people's hands holding various objects. Then, for a larger project I could break out into larger scenes or even surveillance type screenshots. \n",
    "\n",
    "Ultimately, I want this model to be used on video surveillance, however, my model will not be able to generalize or even understand those types of images if that's not the type of data it is trained on. So for future projects, I want to collect surveillance camera data that is more aligned with my goal and that is cohesive in structure.\n",
    "\n",
    "\n",
    "<u> **Computational Power Limitations** </u>\n",
    "Since I am working from a laptop, my computational power is limited. Because of this, I didn't go as far with my computational exploration as I would have liked. If I had more computational power, I probably would have tried some larger Convolutional Neural Network Architectures. Since some of my images are on the larger end, I probably would have also increased the resolution in order for my model to potentially pick up more information in my data. \n",
    "\n",
    "<u> **Time Limitations** </u>\n",
    "If I had more time, I would probably explore larger Convolutional Neural Network Architectures. Deeper (meaning more layers)  and wider (meaning more nodes per layer) Neural Networks have the ability to make better predictions, and learn more about its training data. However, it comes with a price. This would most likely lead to more overfitting than I already had, but the models would probably take an incredibly long time to run. That's time I simply do not have at the moment, but in the future I would like to play around with different architectures and image sizes\n",
    "\n",
    "***\n",
    "### Next Steps\n",
    "\n",
    "For future projects I hope to expand upon this idea. I think this idea is really powerful, and can save lives.\n",
    "\n",
    "<u> **Changing Data** </u>\n",
    "For future exploration, I would like to try using different types of data. I would love to learn how to analyze video data to attempt to be able to detect a threat in real time.\n",
    "\n",
    "I would also like to learn about how data affects these models. I would imagine they impact the model a lot, but what I want to explore is finding out how much variation in data can these Neural Networks take before the variety is too high to make meaningful conclusions / gain insight from the data. \n",
    "\n",
    "<u> **Expanding Model Capacity** </u>\n",
    "In the future, I would love to expand upon my current neural network architectures. I would like to see the capacity of Convolutional Neural Networks on different types of images and different subjects of images as well.\n",
    "\n",
    "<u> **Experiment with Object Detection and Multi-Class Classification** </u>\n",
    "The last thing I am interested in pursuing in the future is Object Detection or having a model try to find and return the location in the image that the object is being found. That is a step above what I am currently working on.\n",
    "\n",
    "Another area of interest would be multi class classification. So, for example, feeding a model images of all types of handheld objects and having it differentiate between the different objects. I think that would be a valuable area of study because it takes this problem a step further.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
